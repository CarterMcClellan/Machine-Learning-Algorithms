{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem Statement\n",
    "\n",
    "You are given an image of dimension $H$ by $W$, and a set of labels (eg, `cat, tree, sky`) ($\\| \\text{classes}\\| = C$). With Semantic Segmentation, you are expected to label each of the $H \\cdot W$ pixels with the appropriate class.\n",
    "\n",
    "For instance\n",
    "```\n",
    "(image)               (pixel labels)\n",
    "[[0.23, 0.05], ----> [[0, 1],\n",
    " [0.15, 0.03]]        [0, 1]]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Naive Approach\n",
    "A Naive approach might be to use a sliding window over ever region in the image.\n",
    "\n",
    "For instance if the image were \n",
    "```\n",
    "[[0.39, 0.51, 0.19, 0.87],\n",
    " [0.68, 0.27, 0.13, 0.24],\n",
    " [0.45, 0.73, 0.28, 0.18],\n",
    " [0.76, 0.12, 0.43, 0.19]]\n",
    "```\n",
    "\n",
    "Then we might use a 3x3 sliding window to classifying\n",
    "```\n",
    "[[0.39, 0.51],\n",
    " [0.68, 0.27]]\n",
    "```\n",
    "as `0`\n",
    "\n",
    "```\n",
    "[[ 0, '?', '?', '?'],\n",
    " ['?', '?', '?', '?'],\n",
    " ['?', '?', '?', '?'],\n",
    " ['?', '?', '?', '?']]\n",
    "```\n",
    "Classifying\n",
    "```\n",
    "[[0.39, 0.51, 0.19],\n",
    " [0.68, 0.27, 0.13]]\n",
    "```\n",
    "As `1`\n",
    "\n",
    "```\n",
    "[[ 0,  1, '?', '?'],\n",
    " ['?', '?', '?', '?'],\n",
    " ['?', '?', '?', '?'],\n",
    " ['?', '?', '?', '?']]\n",
    "```\n",
    "\n",
    "And so on... This is bad/ naive for 2 important reasons\n",
    "1. The regions share weights. In our example we would be re-applying the same convolutional filters to 4 points `(0, 0), (0, 1), (1, 0), (0, 1)`, which is wasteful.\n",
    "2. Its slow! We are operating at $O(H \\cdot W \\cdot N)$ complexity (where $N$ is the compelxity of making a single inference)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Good Approach\n",
    "Our last approach worked it was just super wasteful because we computed each region independently, so what if instead we computed every region as once. How?\n",
    "\n",
    "Pretty simple. Pass an image through a couple of convolutional layers to create a separate channel for each possible class, then take the max over the channel dimension and back propogate, averaging cross entropy across every pixel.\n",
    "\n",
    "```\n",
    "img (3,W,H) -> conv1 (D,W,H) -> conv2 (D,W,H) -> ... ->  convN(C, W, H) -> max((C,W, H)) -> (1, W, H)\n",
    "```\n",
    "\n",
    "This all seems pretty good but there is one crucial weakness. Number of parameters. Aka the network is really big.\n",
    "\n",
    "The number of parameters in a single convolutional layer is \n",
    "\n",
    "$$((W \\cdot H \\cdot I) + 1) \\cdot O$$\n",
    "\n",
    "Where $I$ is the input number of channels and $O$ is the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Given\n",
      "        1000 x 2000 image \n",
      "        10 convolutional layers\n",
      "        4 as the intermeddiate channel size\n",
      "        5 as the number of classes\n",
      "    \n",
      "    There would be 320,000,041 parameters\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "def good_approach_complexity(W, H, D, C, N):\n",
    "    n_params = 0\n",
    "    I = 3\n",
    "    new_channel = [D] * (N-1) + [C]\n",
    "    for O in new_channel:\n",
    "        n_params += ((W * H * I) + 1) * O\n",
    "        I = O\n",
    "    \n",
    "    s = \"\"\"\n",
    "    Given\n",
    "        {W} x {H} image \n",
    "        {N} convolutional layers\n",
    "        {D} as the intermeddiate channel size\n",
    "        {C} as the number of classes\n",
    "    \n",
    "    There would be {n_params:,} parameters\n",
    "    \"\"\".format(W=W, H=H, N=N, D=D, C=C, n_params=n_params)\n",
    "    \n",
    "    print(s)\n",
    "    \n",
    "good_approach_complexity(W=1000, H=2000, D=4, C=5, N=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Better Approach\n",
    "\n",
    "So we liked the last approach its just too complex. So how do we fix it? Its pretty simple actual, we just want to reduce the number of features we are working with, so we can use downsampling to reduce the height and width of the image, then upsampling towards the end, to enlarge the image back to its original dimensions.\n",
    "\n",
    "```\n",
    "img (3, W, H) -> downsample (D, W/2, H/2) -> downsample (D, H/4, W/4) -> upsample (D, H/2, W/2) \n",
    "\n",
    "-> upsample (D, H, W) -> (1, W, H)\n",
    "```\n",
    "For downsampling techniques we can use either\n",
    "- pooling\n",
    "- strided convolution\n",
    "\n",
    "And for upsampling techniques we can use\n",
    "- transpose convolution\n",
    "\n",
    "Note that this approach is called a **U-Net**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "- [CS 231n Lecture 11 - Detection and Segmentation](https://www.youtube.com/watch?v=nDPWywWRIRo)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
