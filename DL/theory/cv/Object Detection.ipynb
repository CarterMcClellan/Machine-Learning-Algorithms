{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem Statement\n",
    "You are given an image of dimension $H$ by $W$, and a set of labels (eg, `cat, tree, sky`) $(\\| \\text{classes}\\| = C)$. Your goal is to predict the image class, and to return a set of coordinates which bounds the object in the image. Except this time, there are a variable number of things in the image. Could be 1, could be 12, you do not know ahead of time.\n",
    "\n",
    "For instance,\n",
    "```\n",
    "(image)               # classification, (x, y, w, h)\n",
    "[[0.23, 0.05], ---->  (cat, [1, 0, 1, 1])\n",
    " [0.15, 0.03]]        \n",
    "```\n",
    "Or\n",
    "```\n",
    "(image)               # classification, (x, y, w, h)\n",
    "[[0.23, 0.05], ---->  (cat, [1, 1, 1, 1]), (dog, [0, 0, 1, 1)\n",
    " [0.15, 0.03]]        \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Approach - Sliding Window\n",
    "Fix some sliding window, (eg 2x2), and iterate through the image passing that window to the CNN, where the window is classified as `dog, cat` or `background`\n",
    "\n",
    "The biggest, most obvious problem is how do we choose the crop? In order to tackle this problem with a brute force approach we would need to try 10,000+ different window sizes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Good Approach - Region Proposals\n",
    "Within traditional computer vision there are algorithms which find regions likely to contain an object (note that this is all traditional CV, using things like image gradients, edge detection, etc...). These methods will spit out 1000-2000 potential regions in 1-2 seconds, with lots of noise but very high recall, meaning that if an object exists within the image, it is likely to be proposed as a region.\n",
    "\n",
    "We now have reduced the number of things to run inference on from several million to several thousand, making the problem much more tractable. This idea all came together in a paper called **R-CNN**\n",
    "\n",
    "But how do we handle variable sizes? Due to the fully connected layers in the network, all images are expected to have the same shape, so we first have to warp the image regions to a pixel $H$ and $W$ before running the same 2 step process we are used to seeing in **Classification + Localization**, classifying the image, and predicting the bounding box (sometimes trimming slightly)\n",
    "\n",
    "So what are the problems\n",
    "- It is still slow. We still have thousands of regions which we need to iterate through. (30 sec - 1 minute inference)\n",
    "- We aren't learning region proposals so if that is a bottlneck in performance we arent going to improve very much.\n",
    "- Training takes a long time. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Better Approach - Fast R-CNN\n",
    "\n",
    "To account for some of the slowness in the previous step we are going to create a high resolution feature map for the entire image, which we can then reuse. Thus rather than taking crops directly from the image, we can take crops from the feature map.\n",
    "\n",
    "Before (R-CNN)\n",
    "\n",
    "```\n",
    "region-proposals -> crop image regions -> pass regions through network\n",
    "```\n",
    "\n",
    "After (Fast R-CNN)\n",
    "\n",
    "```\n",
    "region-proposals -> crop feature map regions\n",
    "```\n",
    "\n",
    "Note that the steps from here are then all the same\n",
    "- region features must be rescaled to squares\n",
    "- rescaled features are then passed through 2 separate fully connected layers (classification and bounding box)\n",
    "\n",
    "This is now muuch faster (inference taking .25 - .5 seconds, rather than 30 - 60 seconds!)\n",
    "\n",
    "Problem\n",
    "- Region proposal is now a bottleneck (still takes around 2 seconds)\n",
    "- We still arent learning region proposals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Even Better Approach - Faster R-CNN\n",
    "\n",
    "Similar to the Fast R-CNN, except now we have 2 additional fully connected networks which preceed the Classifcation and Bounding Box layers. We call these 2 layers the Region Proposal Network (RPN) because they\n",
    "1. Identify whether or not a region contains an object\n",
    "2. Identify the bounding box within the region.\n",
    "\n",
    "This is the primary distinction between Fast and Faster R-CNN, but it does create complications as we are using 1 feature map for 4 different tasks\n",
    "1. Identify object not object.\n",
    "2. Identify bounding box.\n",
    "3. Classify object within region.\n",
    "4. Trim bounding box as necessary.\n",
    "\n",
    "And as we already alluded to, increasing the number of tasks in Multi-Task learning increases the difficulty in training the network.\n",
    "\n",
    "But its very fast now (inference taking .25 - .5 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternatives - YOLO/ SSD\n",
    "What if we eliminated the \"region proposal\" component altogether, instead \n",
    "- breaking the image up into a $7x7$ grid\n",
    "- iterating through all 49 regions\n",
    "- iterating through 5 potential \"base boxes\" (rectangle of different orientation within the grid)\n",
    "    - looking to expand each of those regions by some fixed amount ($dx, dy, dh, dw$)\n",
    "- finally giving a classification which reflects the confidence in that region.\n",
    "\n",
    "The output then being a tuple of 49 x 5 x 5\n",
    "- 49 for the 49 different regions\n",
    "- 5 for the 5 different potential base boxes we start with\n",
    "- 5 for the tuples of 5 tied to each base box (confidence, ($dx, dy, dh, dw$))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparisons\n",
    "- YOLO and SSD are much faster but not as accurate\n",
    "- Faster R-CNN is slower but more accurate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aside\n",
    "- The R in R-CNN stands for region\n",
    "- YOLO stands for \"you only look once\"\n",
    "- SSD stands for \"single shot detection\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
